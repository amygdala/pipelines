name: Automl eval threshold
inputs:
- name: gcp_project_id
  type: String
- name: gcp_region
  type: String
- name: model_display_name
  type: String
- name: bucket_name
  type: String
- name: gcs_path
  type: String
- name: api_endpoint
  type: String
  optional: true
- name: thresholds
  type: String
  default: '{}'
  optional: true
- name: confidence_threshold
  type: Float
  default: '0.5'
  optional: true
outputs:
- name: deploy
  type: Boolean
implementation:
  container:
    image: python:3.7
    command:
    - python3
    - -u
    - -c
    - "from typing import NamedTuple\n\ndef automl_eval_threshold(\n\tgcp_project_id:\
      \ str,\n\tgcp_region: str,\n  model_display_name: str,\n  bucket_name: str,\n\
      \  gcs_path: str,\n  api_endpoint: str = None,\n  # eval_info_string: str =\
      \ None,\n  thresholds: str = '{}',\n  confidence_threshold: float = 0.5\n\n\
      ) -> NamedTuple('Outputs', [('deploy', bool)]):\n  import subprocess\n  import\
      \ sys\n  subprocess.run([sys.executable, '-m', 'pip', 'install', 'googleapis-common-protos==1.6.0',\n\
      \      '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'},\
      \ check=True)\n  subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-automl==0.9.0',\n\
      \     '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'},\
      \ check=True)\n  subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-storage',\n\
      \     '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'},\
      \ check=True)\n\n  import google\n  import json\n  import logging\n  import\
      \ pickle\n  from google.api_core.client_options import ClientOptions\n  from\
      \ google.api_core import exceptions\n  from google.cloud import automl_v1beta1\
      \ as automl\n  from google.cloud.automl_v1beta1 import enums\n  from google.cloud\
      \ import storage\n\n  def get_string_from_gcs(project, bucket_name, gcs_path):\n\
      \    logging.info('Using bucket {} and path {}'.format(bucket_name, gcs_path))\n\
      \    storage_client = storage.Client(project=project)\n    bucket = storage_client.get_bucket(bucket_name)\n\
      \    blob = bucket.blob(gcs_path)\n    return blob.download_as_string()\n\n\
      \  logging.getLogger().setLevel(logging.INFO)  # TODO: make level configurable\n\
      \  # TODO: we could instead check for region 'eu' and use 'eu-automl.googleapis.com:443'endpoint\n\
      \  # in that case, instead of requiring endpoint to be specified.\n  if api_endpoint:\n\
      \    client_options = ClientOptions(api_endpoint=api_endpoint)\n    client =\
      \ automl.TablesClient(project=gcp_project_id, region=gcp_region,\n        client_options=client_options)\n\
      \  else:\n    client = automl.TablesClient(project=gcp_project_id, region=gcp_region)\n\
      \n  try:\n    au_prc = None\n    recall = None\n    precision = None\n    f1_score\
      \ = None\n    au_roc = None\n    log_loss = None\n    # add regression metrics...,\
      \ confusion matrix stuff for binary classif case..\n\n    eval_string = get_string_from_gcs(gcp_project_id,\
      \ bucket_name, gcs_path)\n    eval_info = pickle.loads(eval_string)\n    multiclass\
      \ = True  # aju temp testing\n    # TODO:\n    # Figure out what kind of eval\
      \ it is...\n\n    if multiclass:\n      example_count = eval_info[0].evaluated_example_count\n\
      \      print('Looking for example_count {}'.format(example_count))\n      for\
      \ e in eval_info[1:]:  # we know we don't want the first elt\n        if e.evaluated_example_count\
      \ == example_count:\n          # print('found relevant eval {}'.format(e))\n\
      \          # TODO: which position threshold ?\n          au_prc = e.classification_evaluation_metrics.au_prc\n\
      \          au_roc = e.classification_evaluation_metrics.au_roc\n          log_loss\
      \ = e.classification_evaluation_metrics.log_loss\n          logging.info('got:\
      \ au_prc {}, au_roc {}, log_loss {}'.format(\n              au_prc, au_roc,\
      \ log_loss))\n          for i in e.classification_evaluation_metrics.confidence_metrics_entry:\n\
      \            if i.confidence_threshold >= confidence_threshold:\n          \
      \    recall = i.recall\n              precision = i.precision\n            \
      \  f1_score = i.f1_score\n              logging.info('got recall {}, precision\
      \ {}, f1_score {}'.format(\n                  recall, precision, f1_score))\n\
      \              break\n          break\n    # Get the confidence_metrics_entry\
      \ with given confidence threshold\n    # Grab the metrics and compare with those\
      \ in 'thresholds'\n    return True  # temp..\n  except Exception as e:\n   \
      \ logging.warning(e)\n    return True\n\ndef _serialize_bool(bool_value: bool)\
      \ -> str:\n    if isinstance(bool_value, str):\n        return bool_value\n\
      \    if not isinstance(bool_value, bool):\n        raise TypeError('Value \"\
      {}\" has type \"{}\" instead of bool.'.format(str(bool_value), str(type(bool_value))))\n\
      \    return str(bool_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Automl\
      \ eval threshold', description='')\n_parser.add_argument(\"--gcp-project-id\"\
      , dest=\"gcp_project_id\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--gcp-region\", dest=\"gcp_region\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-display-name\"\
      , dest=\"model_display_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--bucket-name\", dest=\"bucket_name\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--gcs-path\", dest=\"gcs_path\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --api-endpoint\", dest=\"api_endpoint\", type=str, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--thresholds\", dest=\"thresholds\", type=str, required=False,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--confidence-threshold\"\
      , dest=\"confidence_threshold\", type=float, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
      \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = automl_eval_threshold(**_parsed_args)\n\n\
      if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):\n    _outputs\
      \ = [_outputs]\n\n_output_serializers = [\n    _serialize_bool\n]\n\nimport\
      \ os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
      \    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n\
      \        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --gcp-project-id
    - inputValue: gcp_project_id
    - --gcp-region
    - inputValue: gcp_region
    - --model-display-name
    - inputValue: model_display_name
    - --bucket-name
    - inputValue: bucket_name
    - --gcs-path
    - inputValue: gcs_path
    - if:
        cond:
          isPresent: api_endpoint
        then:
        - --api-endpoint
        - inputValue: api_endpoint
    - if:
        cond:
          isPresent: thresholds
        then:
        - --thresholds
        - inputValue: thresholds
    - if:
        cond:
          isPresent: confidence_threshold
        then:
        - --confidence-threshold
        - inputValue: confidence_threshold
    - '----output-paths'
    - outputPath: deploy
